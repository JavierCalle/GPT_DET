{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06284b2f",
   "metadata": {},
   "source": [
    "## predictor 3 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae9fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef32f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('entrenamiento_lsp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "393fcae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>esia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['verse', '1', 'feisty', 'beyoncé', 'im', 'a',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['alaina', 'sixtrye', 'is', 'a', 'human', 'fem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['the', 'ora01031', 'error', 'can', 'occur', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['nours', 'attitude', 'in', 'this', 'respect',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['in', 'life', 'whatever', 'situation', 'it', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004514</th>\n",
       "      <td>['verse', '1', 'in', 'a', 'small', 'town', 'in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004515</th>\n",
       "      <td>['when', 'someone', 'does', 'something', 'wron...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004516</th>\n",
       "      <td>['rnli', 'is', 'spending', '44m', 'to', 'repla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004517</th>\n",
       "      <td>['instead', 'of', 'using', 'paddingleft', 'on'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004518</th>\n",
       "      <td>['adrian', 'petersons', 'twoyearold', 'son', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004519 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  esia\n",
       "0        ['verse', '1', 'feisty', 'beyoncé', 'im', 'a',...     1\n",
       "1        ['alaina', 'sixtrye', 'is', 'a', 'human', 'fem...     1\n",
       "2        ['the', 'ora01031', 'error', 'can', 'occur', '...     1\n",
       "3        ['nours', 'attitude', 'in', 'this', 'respect',...     0\n",
       "4        ['in', 'life', 'whatever', 'situation', 'it', ...     0\n",
       "...                                                    ...   ...\n",
       "1004514  ['verse', '1', 'in', 'a', 'small', 'town', 'in...     1\n",
       "1004515  ['when', 'someone', 'does', 'something', 'wron...     1\n",
       "1004516  ['rnli', 'is', 'spending', '44m', 'to', 'repla...     1\n",
       "1004517  ['instead', 'of', 'using', 'paddingleft', 'on'...     1\n",
       "1004518  ['adrian', 'petersons', 'twoyearold', 'son', '...     1\n",
       "\n",
       "[1004519 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c885e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oreka\\anaconda4\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89     58794\n",
      "           1       0.95      0.96      0.96    142110\n",
      "\n",
      "    accuracy                           0.94    200904\n",
      "   macro avg       0.93      0.92      0.92    200904\n",
      "weighted avg       0.94      0.94      0.94    200904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tomar una muestra representativa de tus datos (por ejemplo, el 10% de ellos)\n",
    "sample_data = data.sample(frac=0.10, random_state=42)\n",
    "\n",
    "# División de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_data['text'], sample_data['esia'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir texto a características numéricas usando TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Entrenar un modelo de regresión logística con la muestra\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predicciones y evaluación para regresión logística\n",
    "y_pred_lr = clf_lr.predict(X_test_vec)\n",
    "print(\"Resultados Regresión Logística:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Entrenar un modelo SVM con la muestra\n",
    "clf_svm = SVC(kernel='linear')\n",
    "clf_svm.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predicciones y evaluación para SVM\n",
    "y_pred_svm = clf_svm.predict(X_test_vec)\n",
    "print(\"Resultados SVM:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa0253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de que el texto haya sido generado por una IA: 16.70%\n"
     ]
    }
   ],
   "source": [
    "def probabilidad_ia(texto, vectorizer, clasificador):\n",
    "    # Transformar el texto con el vectorizador\n",
    "    texto_vec = vectorizer.transform([texto])\n",
    "    \n",
    "    # Obtener las probabilidades\n",
    "    prob = clasificador.predict_proba(texto_vec)\n",
    "    \n",
    "    # Devolver la probabilidad de que sea IA\n",
    "    return prob[0][1]\n",
    "\n",
    "texto_nuevo = \"Marguerite Priola (1849–1876) was a French operatic soprano. She made her debut in 1869 in Paris as the Messenger of Peace in the first French production of Wagner's Rienzi at the Théâtre Lyrique. She enjoyed a successful career at the Opéra-Comique until 1874, performing mainly coloratura soprano roles. There she created several roles, including Princess Elsbeth in Offenbach's Fantasio, Maritana in Massenet's Don César de Bazan, and Javotte in Le roi l'a dit by Delibes. In 1876, she joined the Opéra de Marseille, where she appeared as Philine in Mignon by Ambroise Thomas. Unable to use her voice to its full potential due to illness, she was booed throughout the performance. The illness developed into a serious outbreak of typhoid fever and she died three weeks later at the age of 27. This 1873 portrait, taken by the French photographer Alexandre Quinet, shows Priola in her role in Le Roi l'a dit.\"\n",
    "prob = probabilidad_ia(texto_nuevo, vectorizer, clf)\n",
    "print(f\"Probabilidad de que el texto haya sido generado por una IA: {prob*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d974bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_text = \"The French Revolution began in 1789 and lasted until the rise of Napoleon Bonaparte in 1799.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ac3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_fi_text = \"By the year 3050, humans had established colonies on Mars and were beginning to terraform the planet.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5adc47b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "technical_text = \"Machine learning is a branch of artificial intelligence that focuses on the development of algorithms that allow machines to learn from data.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e34e3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "poetic_text = \"Beneath the mantle of the night sky, the stars shine with a gleam reflecting humanity's dreams.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3068049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_text = \"The internet of emotions has become the next evolutionary step in technology, where devices can detect and respond to human emotions in real-time.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb0f6d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that the text (Historical) was generated by AI: 71.11%\n",
      "Probability that the text (Science Fiction) was generated by AI: 19.82%\n",
      "Probability that the text (Technical) was generated by AI: 54.46%\n",
      "Probability that the text (Poetic) was generated by AI: 79.02%\n",
      "Probability that the text (Generated by AI) was generated by AI: 32.27%\n"
     ]
    }
   ],
   "source": [
    "texts = [historical_text, sci_fi_text, technical_text, poetic_text, ai_text]\n",
    "names = [\"Historical\", \"Science Fiction\", \"Technical\", \"Poetic\", \"Generated by AI\"]\n",
    "\n",
    "for name, text in zip(names, texts):\n",
    "    prob = probabilidad_ia(text, vectorizer, clf)\n",
    "    print(f\"Probability that the text ({name}) was generated by AI: {prob*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abd93a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_txt1 = \"The SS Princess Alice sank on 3 September 1878 after a collision with the collier vessel SS Bywell Castle on the River Thames. Between 600 and 700 people died, all from the paddle steamer, in the greatest loss of life of any British inland waterway shipping accident. Princess Alice was owned by the London Steamboat Co and captained by William R. H. Grinstead.\"\n",
    "wiki_txt2 = \"Marguerite Priola (1849–1876) was a French operatic soprano. She made her debut in 1869 in Paris as the Messenger of Peace in the first French production of Wagner's Rienzi at the Théâtre Lyrique. She enjoyed a successful career at the Opéra-Comique until 1874, performing mainly coloratura soprano roles. There she created several roles, including Princess Elsbeth in Offenbach's Fantasio, Maritana in Massenet's Don César de Bazan, and Javotte in Le roi l'a dit by Delibes\"\n",
    "wiki_txt3 = \"Verdi was commissioned by the Teatro La Fenice in Venice to write an opera, but finding the right subject took some time, and the composer worked with the inexperienced Piave in shaping first one and then another drama by Hugo into an acceptable libretto. As musicologist Roger Parker notes, the composer intervened on several important points, insisting for example that the role of Ernani be sung by a tenor (rather than by a contralto as had originally been planned)\"\n",
    "wiki_txt4 = \"Alzira is an opera in a prologue and two acts by Giuseppe Verdi to an Italian libretto by Salvatore Cammarano, based on the 1736 play Alzire, ou les Américains by Voltaire.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d06610a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that the text (wiki_txt1) was generated by AI: 16.46%\n",
      "Probability that the text (wiki_txt2) was generated by AI: 15.87%\n",
      "Probability that the text (wiki_txt3) was generated by AI: 14.73%\n",
      "Probability that the text (wiki_txt4) was generated by AI: 18.55%\n"
     ]
    }
   ],
   "source": [
    "texts = [wiki_txt1, wiki_txt2, wiki_txt3, wiki_txt4]\n",
    "names = [\"wiki_txt1\", \"wiki_txt2\", \"wiki_txt3\", \"wiki_txt4\"]\n",
    "\n",
    "for name, text in zip(names, texts):\n",
    "    prob = probabilidad_ia(text, vectorizer, clf)\n",
    "    print(f\"Probability that the text ({name}) was generated by AI: {prob*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f700945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that the text (wiki_txt1) was generated by AI: 16.46%\n",
      "Probability that the text (wiki_txt2) was generated by AI: 15.87%\n",
      "Probability that the text (wiki_txt3) was generated by AI: 14.73%\n",
      "Probability that the text (wiki_txt4) was generated by AI: 18.55%\n"
     ]
    }
   ],
   "source": [
    "texts = [wiki_txt1, wiki_txt2, wiki_txt3, wiki_txt4]\n",
    "names = [\"wiki_txt1\", \"wiki_txt2\", \"wiki_txt3\", \"wiki_txt4\"]\n",
    "\n",
    "for name, text in zip(names, texts):\n",
    "    prob = probabilidad_ia(text, vectorizer, clf)\n",
    "    print(f\"Probability that the text ({name}) was generated by AI: {prob*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f171eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
